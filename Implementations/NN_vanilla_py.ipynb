{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, \n",
    "                 input_size, hidden_size, output_size, \n",
    "                 learning_rate=0.1):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights between input->hidden and hidden->output layers\n",
    "        self.weights_ih = [[random.uniform(-0.5, 0.5)] * input_size for _ in range(hidden_size)]\n",
    "        self.weights_ho = [[random.uniform(-0.5, 0.5)] * hidden_size for _ in range(output_size)]\n",
    "\n",
    "        self.bias_hidden = [random.uniform(-0.5, 0.5) for _ in range(hidden_size)]\n",
    "        self.bias_output = [random.uniform(-0.5, 0.5) for _ in range(output_size)]\n",
    "\n",
    "        # Cache for storing values during forward pass (needed for backpropagation)\n",
    "        self.hidden_outputs = None\n",
    "        self.final_outputs = None\n",
    "        self.inputs = None\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        # prevent overflow for large -ve number\n",
    "        if x < -700: return 0\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1-x)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Hidden layer activation\n",
    "        self.hidden_outputs = [0] * self.hidden_size\n",
    "        for i in range(self.hidden_size):\n",
    "            weighted_sum = self.bias_hidden[i]\n",
    "            for j in range(self.input_size):\n",
    "                weighted_sum += inputs[j] + self.weights_ih[i][j]\n",
    "            \n",
    "            self.hidden_outputs[i] = self.sigmoid(weighted_sum)\n",
    "        \n",
    "        self.final_outputs = [0] * self.output_size\n",
    "        for i in range(self.output_size):\n",
    "            weighted_sum = self.bias_output[i]\n",
    "            for j in range(self.hidden_size):\n",
    "                weighted_sum += self.hidden_outputs[j] * self.weights_ho[i][j]\n",
    "            \n",
    "            self.final_outputs[i] = self.sigmoid(weighted_sum)\n",
    "        \n",
    "        return self.final_outputs\n",
    "    \n",
    "    def backpropagate(self, targets):\n",
    "        # Calculate Output layer error\n",
    "        output_errors = [0] * self.output_size\n",
    "        for i in range(self.output_size):\n",
    "            # Error = (tgt - op) * sigmoid_derivative(op)\n",
    "            output_errors[i] = (targets[i] - self.final_outputs[i]) * self.sigmoid_derivative(self.final_outputs[i])\n",
    "        \n",
    "        # calculate hidden layer error\n",
    "        hidden_error = [0] * self.hidden_size\n",
    "        for i in range(self.hidden_size):\n",
    "            error = 0\n",
    "            # sum of error from each output neuron\n",
    "            for j in range(self.output_size):\n",
    "                error += output_errors[j] * self.weights_ho[j][i]\n",
    "            hidden_error[i] = error *self.sigmoid_derivative(self.hidden_outputs[i])\n",
    "\n",
    "        # Update weight between hidden and output layer\n",
    "        for i in range(self.output_size):\n",
    "            for j in range(self.hidden_size):\n",
    "                #  weight_change = learning_rate * error * input\n",
    "                self.weights_ho[i][j] += self.learning_rate * output_errors[i] * self.hidden_outputs[j]\n",
    "            self.bias_output[i] += self.learning_rate * output_errors[i]\n",
    "\n",
    "        for i in range(self.hidden_size):\n",
    "            for j in range(self.input_size):\n",
    "                self.weights_ih[i][j] += self.learning_rate * hidden_error[i] * self.inputs[j]\n",
    "            self.bias_hidden[i] += self.learning_rate * hidden_error[i]\n",
    "    \n",
    "    def train(self, \n",
    "              training_data, targets, \n",
    "              epochs):\n",
    "        for epoch in range(epochs):\n",
    "            total_error = 0\n",
    "            \n",
    "            for i in range(len(training_data)):\n",
    "                # forward pass\n",
    "                outputs = self.forward(training_data[i])\n",
    "\n",
    "                # mse\n",
    "                error = sum([\n",
    "                    (targets[i][j] - outputs[j]) ** 2 for j in range(len(outputs))\n",
    "                ]) / len(outputs)\n",
    "                total_error += error\n",
    "\n",
    "                # backend pass\n",
    "                self.backpropagate(targets[i])\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Error: {total_error / len(training_data)}\")\n",
    "\n",
    "    def predict(self, intputs):\n",
    "        return self.forward(intputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Error: 0.3105624439955551\n",
      "Epoch 100, Error: 0.26158264759309935\n",
      "Epoch 200, Error: 0.2582664561220185\n",
      "Epoch 300, Error: 0.25500989070067054\n",
      "Epoch 400, Error: 0.25220244990711266\n",
      "Epoch 500, Error: 0.25000622489037067\n",
      "Epoch 600, Error: 0.24841935763014403\n",
      "Epoch 700, Error: 0.24734042808343817\n",
      "Epoch 800, Error: 0.2466222808603685\n",
      "Epoch 900, Error: 0.24613484485501477\n",
      "Epoch 1000, Error: 0.24578807793772314\n",
      "Epoch 1100, Error: 0.2455258756514423\n",
      "Epoch 1200, Error: 0.24531453058862668\n",
      "Epoch 1300, Error: 0.2451338658297102\n",
      "Epoch 1400, Error: 0.24497165582846145\n",
      "Epoch 1500, Error: 0.2448203522329112\n",
      "Epoch 1600, Error: 0.24467520012539437\n",
      "Epoch 1700, Error: 0.24453314933994744\n",
      "Epoch 1800, Error: 0.24439221475863815\n",
      "Epoch 1900, Error: 0.24425109209807921\n",
      "Epoch 2000, Error: 0.2441089216614506\n",
      "Epoch 2100, Error: 0.24396513968468733\n",
      "Epoch 2200, Error: 0.2438193827568945\n",
      "Epoch 2300, Error: 0.2436714251432573\n",
      "Epoch 2400, Error: 0.24352113695146935\n",
      "Epoch 2500, Error: 0.24336845576861524\n",
      "Epoch 2600, Error: 0.24321336716259775\n",
      "Epoch 2700, Error: 0.24305589111242532\n",
      "Epoch 2800, Error: 0.24289607246120615\n",
      "Epoch 2900, Error: 0.24273397413302564\n",
      "Epoch 3000, Error: 0.24256967226946757\n",
      "Epoch 3100, Error: 0.24240325271170493\n",
      "Epoch 3200, Error: 0.2422348084328853\n",
      "Epoch 3300, Error: 0.24206443764567023\n",
      "Epoch 3400, Error: 0.24189224239152857\n",
      "Epoch 3500, Error: 0.2417183274747562\n",
      "Epoch 3600, Error: 0.24154279964345565\n",
      "Epoch 3700, Error: 0.241365766947395\n",
      "Epoch 3800, Error: 0.2411873382223281\n",
      "Epoch 3900, Error: 0.2410076226644945\n",
      "Epoch 4000, Error: 0.24082672946921124\n",
      "Epoch 4100, Error: 0.24064476751492325\n",
      "Epoch 4200, Error: 0.24046184507951404\n",
      "Epoch 4300, Error: 0.24027806957969516\n",
      "Epoch 4400, Error: 0.24009354732725513\n",
      "Epoch 4500, Error: 0.23990838329812603\n",
      "Epoch 4600, Error: 0.2397226809118378\n",
      "Epoch 4700, Error: 0.23953654182010808\n",
      "Epoch 4800, Error: 0.23935006570416112\n",
      "Epoch 4900, Error: 0.23916335008095924\n",
      "Epoch 5000, Error: 0.23897649011893474\n",
      "Epoch 5100, Error: 0.23878957846407303\n",
      "Epoch 5200, Error: 0.23860270507730727\n",
      "Epoch 5300, Error: 0.2384159570842491\n",
      "Epoch 5400, Error: 0.2382294186382487\n",
      "Epoch 5500, Error: 0.2380431707976769\n",
      "Epoch 5600, Error: 0.2378572914182347\n",
      "Epoch 5700, Error: 0.23767185506090932\n",
      "Epoch 5800, Error: 0.2374869329160427\n",
      "Epoch 5900, Error: 0.2373025927438035\n",
      "Epoch 6000, Error: 0.2371188988311453\n",
      "Epoch 6100, Error: 0.2369359119651675\n",
      "Epoch 6200, Error: 0.23675368942260874\n",
      "Epoch 6300, Error: 0.2365722849750371\n",
      "Epoch 6400, Error: 0.23639174890914183\n",
      "Epoch 6500, Error: 0.23621212806139744\n",
      "Epoch 6600, Error: 0.23603346586625043\n",
      "Epoch 6700, Error: 0.23585580241687412\n",
      "Epoch 6800, Error: 0.23567917453745058\n",
      "Epoch 6900, Error: 0.23550361586590127\n",
      "Epoch 7000, Error: 0.2353291569459043\n",
      "Epoch 7100, Error: 0.23515582532705281\n",
      "Epoch 7200, Error: 0.23498364567197744\n",
      "Epoch 7300, Error: 0.23481263986927586\n",
      "Epoch 7400, Error: 0.23464282715111914\n",
      "Epoch 7500, Error: 0.23447422421442643\n",
      "Epoch 7600, Error: 0.23430684534457508\n",
      "Epoch 7700, Error: 0.23414070254064243\n",
      "Epoch 7800, Error: 0.23397580564126239\n",
      "Epoch 7900, Error: 0.23381216245022876\n",
      "Epoch 8000, Error: 0.23364977886109162\n",
      "Epoch 8100, Error: 0.23348865898000745\n",
      "Epoch 8200, Error: 0.23332880524624677\n",
      "Epoch 8300, Error: 0.2331702185497994\n",
      "Epoch 8400, Error: 0.23301289834560315\n",
      "Epoch 8500, Error: 0.23285684276400598\n",
      "Epoch 8600, Error: 0.23270204871712502\n",
      "Epoch 8700, Error: 0.23254851200085352\n",
      "Epoch 8800, Error: 0.23239622739230398\n",
      "Epoch 8900, Error: 0.23224518874256683\n",
      "Epoch 9000, Error: 0.23209538906466223\n",
      "Epoch 9100, Error: 0.2319468206166987\n",
      "Epoch 9200, Error: 0.2317994749801832\n",
      "Epoch 9300, Error: 0.23165334313356917\n",
      "Epoch 9400, Error: 0.23150841552109103\n",
      "Epoch 9500, Error: 0.23136468211700312\n",
      "Epoch 9600, Error: 0.2312221324853306\n",
      "Epoch 9700, Error: 0.23108075583530718\n",
      "Epoch 9800, Error: 0.23094054107262985\n",
      "Epoch 9900, Error: 0.23080147684672425\n",
      "Input: [0, 0], Predicted: 0.5884, Target: 0\n",
      "Input: [0, 1], Predicted: 0.5564, Target: 1\n",
      "Input: [1, 0], Predicted: 0.5564, Target: 1\n",
      "Input: [1, 1], Predicted: 0.3234, Target: 0\n"
     ]
    }
   ],
   "source": [
    "xor_inputs = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "]\n",
    "\n",
    "xor_outputs = [\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "]\n",
    "\n",
    "nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1, learning_rate=0.3)\n",
    "nn.train(xor_inputs, xor_outputs, 10000)\n",
    "\n",
    "for i in range(len(xor_inputs)):\n",
    "    prediction = nn.predict(xor_inputs[i])\n",
    "    print(f\"Input: {xor_inputs[i]}, Predicted: {prediction[0]:.4f}, Target: {xor_outputs[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
